{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in all json files in a directory and create 1 combined file for app\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in all the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData(loc):\n",
    "    files = []\n",
    "    locDict = {} #a dict to attach the location to each file for later, so that I can sort by filename\n",
    "    for lo in loc:\n",
    "        print(lo)\n",
    "        ff = os.listdir(lo)\n",
    "        for f in ff:\n",
    "            locDict[f] = lo\n",
    "        files.extend(ff)\n",
    "    files = sorted(files, key=str.lower) #sort by filename (which should be the object name as well)\n",
    "    objects = {}\n",
    "    categories = []\n",
    "    for f in files:\n",
    "        if (f[0] != '.'):\n",
    "            print(f)\n",
    "            df = pd.read_json(os.path.join(locDict[f],f),typ='dict', encoding = \"ISO-8859-1\", convert_axes = False)\n",
    "        # had a problem with pandas wanting to automatically convert M60 to a Timestamp!\n",
    "        #     if (f == \"M60.json\"):\n",
    "        #         print(f)\n",
    "        #         print(df)\n",
    "            objects.update(df)\n",
    "            categories.append(df[0]['Category'])\n",
    "        \n",
    "    return objects, categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*From the TileWall files and user object*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TileWallData/objectFiles\n",
      "userObjects\n",
      "Abell1689.json\n",
      "AlphaCentauri.json\n",
      "AndromedaM31.json\n",
      "AntennaeGalaxies.json\n",
      "Aquarius.json\n",
      "Aries.json\n",
      "Betelgeuse.json\n",
      "BlackEyeGalaxyM64.json\n",
      "BodesM81.json\n",
      "BulletCluster.json\n",
      "ButterflyClusterM6.json\n",
      "Cancer.json\n",
      "Canopus.json\n",
      "Capricornus.json\n",
      "CarinaNebula.json\n",
      "Cartwheel.json\n",
      "Cassiopeia.json\n",
      "CassiopeiaA.json\n",
      "CatsEyeNebula.json\n",
      "CentaurusA.json\n",
      "CigarGalaxyM82.json\n",
      "CL002417.json\n",
      "ComaCluster.json\n",
      "CrabNebulaM1.json\n",
      "EagleNebulaM16.json\n",
      "EggNebula.json\n",
      "ElephantsTrunkNebula.json\n",
      "ElGordo.json\n",
      "ESO510G13.json\n",
      "EtaCarinae.json\n",
      "EyesGalaxies.json\n",
      "Fomalhaut.json\n",
      "Gemini.json\n",
      "HelixNebula.json\n",
      "Hercules.json\n",
      "HLTau.json\n",
      "HoagsObject.json\n",
      "HomunculusNebula.json\n",
      "HorseheadNebula.json\n",
      "HubbleDeepField.json\n",
      "HubbleUltraDeepField.json\n",
      "Hydra.json\n",
      "LagoonNebulaM8.json\n",
      "LargeMagellanicCloud.json\n",
      "Leo.json\n",
      "LeoTripletM66Group.json\n",
      "Libra.json\n",
      "Lyra.json\n",
      "M10.json\n",
      "M15.json\n",
      "M2.json\n",
      "M3.json\n",
      "M4.json\n",
      "M5.json\n",
      "M60.json\n",
      "M87akaVirgoA.json\n",
      "M9.json\n",
      "MayallsObject.json\n",
      "MiceGalaxies.json\n",
      "MilkyWayGalacticCenter.json\n",
      "NGC1316akaFornaxA.json\n",
      "NGC3314.json\n",
      "NGC4993LIGOKilonova.json\n",
      "NGC5866M102SpindleGalaxy.json\n",
      "NGC5907.json\n",
      "NGC602.json\n",
      "NGC6050.json\n",
      "Ophiuchus.json\n",
      "Orion.json\n",
      "OrionNebulaM42.json\n",
      "PinwheelM101.json\n",
      "Pisces.json\n",
      "PleiadesM45.json\n",
      "Polaris.json\n",
      "Pollux.json\n",
      "ProximaCentauri.json\n",
      "PtolemyClusterM7.json\n",
      "RCS2032727132623.json\n",
      "RhoOphiuchi.json\n",
      "RingNebulaM57.json\n",
      "RosetteNebula.json\n",
      "Sagittarius.json\n",
      "SagittariusDwarfEllipticalGalaxy.json\n",
      "Scorpius.json\n",
      "Sirius.json\n",
      "SmallMagellanicCloud.json\n",
      "SN1987a.json\n",
      "SombreroGalaxyM104.json\n",
      "StephansQuintet.json\n",
      "TarantulaNebula.json\n",
      "Taurus.json\n",
      "TriangulumGalaxy.json\n",
      "UrsaMajor.json\n",
      "UrsaMinor.json\n",
      "VeilNebula.json\n",
      "Virgo.json\n",
      "Westerlund2.json\n",
      "WhirlpoolM51.json\n"
     ]
    }
   ],
   "source": [
    "loc1 = os.path.join('TileWallData','objectFiles')\n",
    "loc2 = 'userObjects'\n",
    "objects, categories = getData([loc1, loc2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify the unique categories, and create the new dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Constellations', 'Galaxies', 'Galaxy Clusters', 'Nebulae', 'Star Clusters', 'Stars']\n"
     ]
    }
   ],
   "source": [
    "categories = sorted(list(set(categories)), key=str.lower)\n",
    "print(categories)\n",
    "dictOut = {}\n",
    "for c in categories:\n",
    "    dictOut[c] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, o in objects.items():\n",
    "    dictOut[o['Category']].append({key:o})\n",
    "#print(dictOut)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dump this to json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('allObjects.json', 'w') as fp:\n",
    "    json.dump(dictOut, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Put this into a stand-alone python code as well.\n",
    "\n",
    "```jupyter nbconvert --to script [YOUR_NOTEBOOK].ipynb```\n",
    "\n",
    "*NOTE 1: if you run this here, be sure to delete it from the compileObjects.py file.*\n",
    "\n",
    "*NOTE 2: I put all the cells that don't have methods into a method called compileAll.  If you remake the file here, add back that method definition.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook compileObjects.ipynb to script\n",
      "[NbConvertApp] Writing 1908 bytes to compileObjects.py\n"
     ]
    }
   ],
   "source": [
    "#!jupyter nbconvert --to script compileObjects.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
